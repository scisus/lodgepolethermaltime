---
title: "Phenology model conceptual analysis"
author: "C. Susannah Tysor"
date: '2021-08-24'
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, echo = FALSE, message=FALSE}

library(dplyr)
library(ggplot2)
library(zoo)
library(flowers)
library(dplyr)
library(knitr)
library(tidyr)
```



# Conceptual Analysis

This section outlines and justifies some of the choices made in the modeling process, especially regarding priors. Data used to make these choices includes
- corrected daily climate dataset for 1945-2012 described in [Site weather data]

I have a record of days that lodgepole pine were recorded flowering or not flowering during the general flowering period. Trees were observed for several years at several sites and trees were not observed every day and the start or end of the flowering period may have been missed.

The flowering observations ($f_i$) were simplified to three states - before flowering, flowering, past flowering. States are used to infer two of four events (1-last day before flowering, 2-first day flowering, 3-last day flowering, 4-first day past flowering). The amount of forcing accumulated at each event day was calculated as growing degree days with a 5 degree threshold.

I want to know how much forcing after January 1 must accumulate for events 2 and 3 - the flowering state - to occur.

$f_i \sim \mathcal{N}(\phi_i, \sigma)$

I wish to account for several kinds of structure in the data:

- year of observation
- site where tree was grown
- genotype of the tree
- individual tree

as well as censoring and variation due to provenance climate summarised at MAT

So

$\phi_i = \mu + \beta MAT_i + delta_{site,i} + \delta_{year,i} + \delta_{genotype,i} + \delta_{tree,i}$

where $\mu$ is the average amount of forcing it takes for a tree to reach an event and the $\delta$s describe how much each level in each factor (site, prov, year, genotype) is offset from the population mean amount of forcing required to reach the event.

I can account for different types of censoring by modifying the likelihood.

I want priors on parameters to be regularizing and weakly informative.

## Define observational space

There are several thousand observations of each event. Each observation is the amount of forcing units accumulated when the event occurs for a given tree. 

So, how much forcing is accumulated over the year? I use the sites in my study and all possible years in my climate dataset (1945-2012).

```{r, echo = FALSE, fig.caption="Forcing accumulation at all sites 1945-2012.", out.extra = ''}

# forcing units for 16 years and at sites included in this study
forcing <- read.csv('~/Documents/research/lodgepolethermaltime/data/forcing/dailyforc_1945_2012.csv', header=TRUE) 
  
ggplot(forcing, aes(x=DoY, y=sum_forcing, colour = interaction(Site,Year))) +
  geom_line() +
  theme(legend.position = "none") +
  ylab("GDD (\u00B0C)")

```

What are reasonable amounts of forcing? Lodgepole in BC flower in late spring. Flowering occurs in BC, according to Owens (2006)in late May and June. I will generously use May 01 to June 30 as dates to consider.

```{r, echo = FALSE, fig.cap = "Histogram of forcing accumulations May 1 to June 30 at all sites 1945-2012"}
# likely Day of Year limits for flowering
early_limit <- as.numeric(strftime("2020-05-01", format = "%j"))
late_limit <- as.numeric(strftime("2020-06-30", format = "%j"))

ff <- dplyr::filter(forcing, DoY > early_limit & DoY < late_limit)

ggplot(ff, aes(x=sum_forcing)) +
         geom_histogram(bins=60) +
  ggtitle("Range of forcing accummulations May 1 - June 30")
```

```{r, echo = FALSE, fig.cap = "Day of Year of forcing accumulations May 1 to June 30 showing increase through time."}
ggplot(ff, aes(x=DoY, y=sum_forcing, colour = interaction(Site,Year))) +
  geom_line() +
  theme(legend.position = "none") +
  ggtitle("forcing (gdd) accumulated at Day of Year", subtitle = "May 1 - June 30")


```


```{r, echo = FALSE}
# Early and Late
may01 <- as.numeric(strftime("2020-05-01", format = "%j"))
may31 <- as.numeric(strftime("2020-05-31", format = "%j"))

may15 <- as.numeric(strftime("2020-05-15", format = "%j"))
jun30 <- as.numeric(strftime("2020-06-30", format = "%j"))

ffstart <- dplyr::filter(forcing, DoY > may01 & DoY < may31)
range(ffstart$sum_forcing)

ffend <- dplyr::filter(forcing, DoY > may15 & DoY < jun30)
range(ffend$sum_forcing)

```
Flowering is more likely to start in the earlier part of the date range and end in the later part of the date range.
The range of forcing accumulation for May is`r min(ffstart$sum_forcing)` - `r max(ffstart$sum_forcing)` GDD. The range of forcing accumulation from May 15 to June 30 is `r min(ffend$sum_forcing)` - `r max(ffend$sum_forcing)` GDD.

Each event is associated with a year, site, genotype, and genotype. There are 16 years, 7 sites, 259 genotypes, and 748 individual trees (genotypes).

# Model development

$f_i$ are the observations of accumulated forcing. They are positive and continuous and should be between about 0 and 1000 GDD. 

$f_i$'s value can be modeled as coming from a distribution with a mean forcing accumulation ($\phi_i$) and standard deviation $\sigma$ that represents our uncertainty in the observation - how good our temperature measurements are, how good the forcing unit accumulation function is, and whether the event was observed on the correct day, etc. 

## Residual standard deviation 

$\sigma$ could potentially be relatively large because of irregular sampling and compounding errors through censoring, multiple observers, and errors in accumulated forcing. I think an extreme upper limit is probably about 2 weeks of forcing. 

```{r, echo = FALSE}

# get 14 day forcing accumulations

janjun <- forcing %>%
  filter(DoY < late_limit) 


fortforc <- janjun %>%
  group_by(Site, Year) %>%
  reframe(fortforc = rollsum(forcing, 14, fill = NA, align = "right"))

fextreme <- quantile(fortforc$fortforc, 0.99, na.rm = TRUE) #end

```

The amount of forcing that can accumulate over any two week period between January and June can be quite large - 99th percentile is `r fextreme`. The sd required to obtain these values in a normal distribution or the $\nu$ in a student t's distribution is:

```{r, fig.cap = "Histogram of forcing accumulations over 14 day periods January-June. Vertical line at 99th percentile"}

ggplot(fortforc, aes(x=fortforc)) +
  geom_histogram() +
  ggtitle("Forcing accumulation over 14 day periods Jan-Jun") +
  geom_vline(xintercept = fextreme)
```

```{r, fig.caption = "Histogram of a normal distribution with mean zero and sd 50"}
# normal
pnorm(fextreme, 0, sd=60) # sd to cap at extreme #50 prob fine too
hist(rnorm(1000, 0, sd=50), breaks=60) 

# pnorm(feextreme, 0, sd = 40)
# hist(rnorm(1000, 0, sd = 40))

#student
# pt(fextreme, 1)
# hist(rt(1000, 1), breaks = 50)

```

And distributions that produce these standard deviations, for sampling sigma are
```{r}
pnorm(60, 0, 20) # 15 probably lower limit when using 50sd
pt(60, 1)

# pnorm(40, 0, 12)
# pt(55, 1)
```
So,

$f_i ~ \mathcal{N}(\phi_i, \sigma)$

$\sigma \sim |\mathcal{Normal}(0, 50)|$

$\phi_i$ is a function of $\mu$ and the $\delta$ offsets. 

## mu

$\mu$ represents the population average for forcing required to achieve the flowering event of interest. 

```{r}

ffstart <- dplyr::filter(forcing, DoY > may01 & DoY < may31)
range(ffstart$sum_forcing)

ffend <- dplyr::filter(forcing, DoY > may15 & DoY < jun30)
range(ffend$sum_forcing)

ffs1 <- quantile(ffstart$sum_forcing, 0.01)
ffe1 <- quantile(ffend$sum_forcing, 0.01)
ffs99 <- quantile(ffstart$sum_forcing, 0.99)
ffe99 <- quantile(ffend$sum_forcing, 0.99)

```
It must be positive and continuous. Values less 5 and greater than 1000 would be quite unbelievable for any phase.

For starting, values less than `r ffs1` and greater than `r ffs99` would be very surprising.
For finishing, values less than `r ffe1` and greater than `r ffe99` would be very surprising.

### mu start

For start events



```{r}
pnorm(ffs99, mean = (ffs1+ffs99)/2, sd = 60) #start
hist(rnorm(1000, 233, 60), breaks=60)
hist(rt(1000, 25, ncp = 233), breaks=60)

```
$\mu \sim \mathcal{N}(335,85)$

### mu end

For end events:

$\mu \sim \mathcal{N}(555,150)$

```{r}
pnorm(ffe99, mean = (ffe1 + ffe99)/2, sd = 100) #end
hist(rnorm(1000, 438, 100), breaks=60)
```
These are very weakly informative - I could use more detailed prior information from work by Owens regarding dates and heatsums.

### whole period
I could be even broader and use the same prior for both. Because the data is skewed, a skewed distribution, like gamma, might make more sense.

```{r}
ffperiod <- dplyr::filter(forcing, DoY > may01 & DoY < jun30)
range(ffperiod$sum_forcing)

ffp1 <- quantile(ffperiod$sum_forcing, 0.01)
ffp99 <- quantile(ffperiod$sum_forcing, 0.99)

pnorm(ffp99, mean = (ffp1 + ffp99)/2, sd = 100) #end
hist(rnorm(1000, 400, 100), breaks=60)
hist(ff$sum_forcing, breaks=50)
# gamma k shape = mean^2/sd^2
k <- mean(ff$sum_forcing)^2/sd(ff$sum_forcing)^2
# gamma theta scale = sd^2/mean, rate = 1/theta
theta <- sd(ff$sum_forcing)^2/mean(ff$sum_forcing)
hist(brms::rskew_normal(1000, 100, 100, 2), breaks = 50)
hist(rgamma(1000, shape = k, scale = theta), breaks = 50)
hist(rnorm(1000, mean = 400, sd = 100), breaks = 50)
```
Nice thing about gamma distribution is it's always positive, like forcing values, and accommodates skew.


## delta 

The $\delta$ effects are modeled as offsets from $\mu$, thus the superpopulation mean must be 0. Individual effects, however, may vary by $\sigma_{factor}$

A flowering period of 2 weeks for a population would be very long and a flowering period of a week very long for an individual tree, so an effect ($\delta$) that changed the timing of flowering by even a few days would be meaningful. An delta that shifted flowering by 1 weeks would be quite extreme. How much forcing can accumulate in 1 week prior to an event?

```{r}
week_forcing <- janjun %>%
  group_by(Site, Year) %>%
  summarise(sum_forcing_week = zoo::rollsum(forcing, 7))

ggplot(week_forcing, aes(x=sum_forcing_week)) +
  geom_histogram() +
  ggtitle("Forcing accumulation over 1 week periods from January 1 to June 30") +
  geom_vline(xintercept = mean(week_forcing$sum_forcing_week))

# 90th percentile of forcing that can accumulate in a week
wextreme <- quantile(week_forcing$sum_forcing_week, .99) # because forcing accumulates so much faster at the end of june when flowering is quite unlikely, capping at 90%

pnorm(wextreme, mean=0, sd=30) # what sd caps at extreme forcing accumulation


```
`r wextreme` would be a very extreme delta and it would be in the 99th percentile of a normal distribution with mean 0 and standard deviation 45. So to obtain a $\sigma$ of 45, 

```{r}
pnorm(30, mean = 0, sd=9)
pt(45, 1)
```

$\delta_{cluster} \sim \mathcal{N}(0,\sigma_{cluster})$

$\sigma_{cluster} \sim \mathcal{N}(0, 18)$

```{r}
hist(rnorm(1000, mean=0, sd=18), breaks=50) 

```

I've stuck with half normals because while genotype and genotype have hundreds of levels, Site only has 7 and year only 16.

## beta
Beta sampling distribution must include 0 as we don't know if there's an effect and it's centered on 0 because I don't have any reason to believe an effect would be positive or negative. How wide its sampling distribution will be depends realistic forcing ranges and MAT. MAT at my sites ranges from -0.7 to 6.8 $^\circ$C.
If only provenance climate controlled GDD requirements, then maximum size of beta is the maximum accumulated forcing difference between sites divided by the MAT range. 

```{r beta}
forcing %>%
  filter(DoY == 181) %>%
  select(Year, Site, sum_forcing) %>%
  summarise(maxdiff = range(sum_forcing))
```

The maximum difference between sites is about 800 GDD and the temperature difference between provenances is about 8 degrees, so, if MAT expained the entire GDD required, $\beta$ would be about 100.

<!-- But that's a very unrealistic assumption based on everything we know about spring phenology - and the experience of generalized overlap in the seed orchards. I think even 50 would be a shocking result -->

```{r betadist}
sdx = 25
pnorm(100, mean = 0, sd = sdx)
hist(rnorm(1000, 0, sdx))
```
 
## Centering

Factors that have a lot of levels all with limited data, like genotype, will probably sample best if non-centered.

Some of my factors are very unbalanced with some levels very well represented and others not and could benefit from partial decentering. However, brms automatically non-centers everything. If it works, then don't worry here.



