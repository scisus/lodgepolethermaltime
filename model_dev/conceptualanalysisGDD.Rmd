---
title: "Phenology model workflow"
author: "C. Susannah Tysor"
date: '2021-08-24'
output: html_document
---

```{r setup}

library(dplyr)
library(ggplot2)
library(zoo)
library(flowers)
library(dplyr)
library(knitr)

knitr::opts_chunk$set(echo = TRUE)
source('../phenology_functions.R')
```

# Conceptual Analysis

I have a record of days that lodgepole pine were recorded flowering or not flowering during the general flowering period. Trees were not observed every day and the start or end of the flowering period may have been missed.

The flowering observations ($y$) were simplified to three states - before flowering, flowering, past flowering. States are used to infer two of four events (1-last day before flowering, 2-first day flowering, 3-last day flowering, 4-first day past flowering). . The amount of forcing accumulated at each event day was calculated using Risto Sarvas's 1972 curve.

I want to know how much forcing after January 1 must accumulate for events 2 and 3 - the flowering state - to occur.

$y_i \sim \mathcal{N}(f_i, \sigma)$

I wish to account for several kinds of structure in the data:

- year of observation
- site where tree was grown
- provenance the tree's parents were sourced from
- clone identity (multiple ramets of clones are grown at seed orchard sites)

So

$f_i = \mu + delta_{site,i} + \delta_{prov,i} + \delta_{year,i} + \delta_{clone,i}$

where $\mu$ is the average amount of forcing it takes for a tree to reach an event and the $\delta$s describe how much each level in each factor (site, prov, year, clone) is offset from the population mean amount of forcing required to reach the event.

I want priors on parameters to be regularizing and weakly informative.

# Define observational space

There are several thousand observations of each event. Each observation is the amount of forcing units accumulated when the event occurs for a given tree. 

So, how much forcing is accumulated over the year? I use the sites in my study and all possible years in my climate dataset (1945-2012).

```{r}

# forcing units for 15 years and at sites included in this study
forcing <- read.csv('../data/all_clim_PCIC.csv', header=TRUE) %>%
  dplyr::filter(forcing_type=="gdd")

ggplot(forcing, aes(x=DoY, y=sum_forcing, colour = interaction(Site,Year))) +
  geom_line() +
  theme(legend.position = "none") +
  ggtitle("forcing (gdd) accumulated at Day of Year")



```

What are reasonable amounts of forcing? Lodgepole in BC flower in late spring - pollination occurs, according to Owens in late May and June. I will generously set this as May 01 to June 30.

```{r}
# likely Day of Year limits for flowering
early_limit <- as.numeric(strftime("2020-05-01", format = "%j"))
late_limit <- as.numeric(strftime("2020-06-30", format = "%j"))

ff <- dplyr::filter(forcing, DoY > early_limit & DoY < late_limit)

ggplot(ff, aes(x=sum_forcing)) +
         geom_histogram(bins=60) +
  ggtitle("Range of forcing accummulations May 1 - June 30")

ggplot(ff, aes(x=DoY, y=sum_forcing, colour = interaction(Site,Year))) +
  geom_line() +
  theme(legend.position = "none") +
  ggtitle("forcing (gdd) accumulated at Day of Year", subtitle = "May 1 - June 30")
```


```{r}
# Early and Late
may01 <- as.numeric(strftime("2020-05-01", format = "%j"))
may31 <- as.numeric(strftime("2020-05-31", format = "%j"))

may15 <- as.numeric(strftime("2020-05-15", format = "%j"))
jun30 <- as.numeric(strftime("2020-06-30", format = "%j"))

ffstart <- dplyr::filter(forcing, DoY > may01 & DoY < may31)
range(ffstart$sum_forcing)

ffend <- dplyr::filter(forcing, DoY > may15 & DoY < jun30)
range(ffend$sum_forcing)

```
Flowering is more likely to start in the first part (`r range(ffstart$sum_forcing)` forcing units) and end in the second part (`r range(ffend$sum_forcing)` forcing units) of this time period.

Each event is associated with a year, provenance, site, and clone. There are 14 years, 7 sites and provenances, and several hundred clones.


# Construct summary statistics

Histograms of $y_i$ and each $\delta_{cluster}$.

# Model development

$y_i$ are the observations of accumulated forcing. They are positive and continuous and should be between about 0 and 1000. 

$y_i$'s value can be modeled as coming from a distribution with a mean forcing accumulation ($f_i$) and standard deviation $\sigma$ that represents our uncertainty in the observation - how good our temperature measurements are, how good the forcing unit accumulation function is, and whether the event was observed on the correct day. 

## sigma

Sigma could potentially be relatively large because of lackadaisical sampling and compounding errors through censoring, multiple observers, and errors in accumulated forcing measurements. I think an extreme upper limit is probably about 2 weeks of forcing. 

```{r}

# get 7 & 14 day forcing accumulations

janjun <- forcing %>%
  filter(DoY < late_limit) 


fortforc <- janjun %>%
  group_by(Site, Year) %>%
  summarise(fortforc = rollsum(forcing, 14))

# fortforce <- early %>%
#   group_by(Site, Year) %>%
#   summarise(fortforce = rollsum(forcing, 14))

fextreme <- quantile(fortforc$fortforc, 0.99) #end

#feextreme <- quantile(fortforce$fortforce, 0.99) # start

```

The amount of forcing that can accumulate over any two week period between January and June can be quite large - 99th percentile is `r fextreme`. The sd required to obtain these values is

```{r}

ggplot(fortforc, aes(x=fortforc)) +
  geom_histogram() +
  ggtitle("Forcing accumulation over 14 day periods Jan-Jun") +
  geom_vline(xintercept = mean(fortforc$fortforc))

pnorm(fextreme, 0, sd=50) # sd to cap at extreme
hist(rnorm(1000, 0, sd=50), breaks=50) 

# pnorm(feextreme, 0, sd = 40)
# hist(rnorm(1000, 0, sd = 40))


```
And distributions that produce these standard deviations, for sampling sigma are
```{r}
pnorm(50, 0, 15)
pt(80, 1)

pnorm(40, 0, 12)
pt(55, 1)
```
So,

$y_i ~ \mathcal{N}(f_i, \sigma)$

$\sigma \sim |\mathcal{Normal}(0, 50)|$

$f_i$ is a function of $\mu$ and the $\delta$ offsets. 

## mu

$\mu$ represents the population average for forcing required to achieve the flowering event of interest. 

```{r}

ffstart <- dplyr::filter(forcing, DoY > may01 & DoY < may31)
range(ffstart$sum_forcing)

ffend <- dplyr::filter(forcing, DoY > may15 & DoY < jun30)
range(ffend$sum_forcing)

ffs1 <- quantile(ffstart$sum_forcing, 0.01)
ffe1 <- quantile(ffend$sum_forcing, 0.01)
ffs99 <- quantile(ffstart$sum_forcing, 0.99)
ffe99 <- quantile(ffend$sum_forcing, 0.99)

```
It must be positive and continuous. Values less 5 and greater than 1000 would be quite unbelievable for any phase.

For starting, values less than `r ffs1` and greater than `r ffs99` would be very surprising.
For finishing, values less than `r ffe1` and greater than `r ffe99` would be very surprising.

### mu start

For start events



```{r}
pnorm(ffs99, mean = (ffs1+ffs99)/2, sd = 60) #start
hist(rnorm(1000, 233, 60), breaks=60)
hist(rt(1000, 25, ncp = 233), breaks=60)

```
$\mu \sim \mathcal{N}(335,85)$

### mu end

For end events:

$\mu \sim \mathcal{N}(555,150)$

```{r}
pnorm(ffe99, mean = (ffe1 + ffe99)/2, sd = 100) #end
hist(rnorm(1000, 438, 100), breaks=60)
```
These are very weakly informative - I could use more detailed prior information from work by Owens regarding dates and heatsums.

### whole period
I could be even broader and use the same prior for both.

```{r}
ffperiod <- dplyr::filter(forcing, DoY > may01 & DoY < jun30)
range(ffperiod$sum_forcing)

ffp1 <- quantile(ffperiod$sum_forcing, 0.01)
ffp99 <- quantile(ffperiod$sum_forcing, 0.99)

pnorm(ffp99, mean = (ffp1 + ffp99)/2, sd = 100) #end
hist(rnorm(1000, 400, 100), breaks=60)
```


## delta 

The $\delta$ effects are modeled as offsets from $\mu$, thus the superpopulation mean must be 0. Individual effects, however, may vary by $\sigma_{factor}$

A flowering period of 2 weeks for a population would be very long and a flowering period of a week very long for an individual tree, so an effect ($\delta$) that changed the timing of flowering by even a few days would be meaningful. An delta that shifted flowering by 1 weeks would be quite extreme. How much forcing can accumulate in 1 week prior to an event?

[Since there aren't extreme variations in the length of flowering period, using the first part of the flowering period might be a better guide for this. Currently using January - June]

```{r}
week_forcing <- janjun %>%
  group_by(Site, Year) %>%
  summarise(sum_forcing_week = zoo::rollsum(forcing, 7))

ggplot(week_forcing, aes(x=sum_forcing_week)) +
  geom_histogram() +
  ggtitle("Forcing accumulation over 1 week periods from January 1 to June 30") +
  geom_vline(xintercept = mean(week_forcing$sum_forcing_week))

# 90th percentile of forcing that can accumulate in a week
wextreme <- quantile(week_forcing$sum_forcing_week, .99) # because forcing accumulates so much faster at the end of june when flowering is quite unlikely, capping at 90%

pnorm(wextreme, mean=0, sd=30) # what sd caps at extreme forcing accumulation


```
`r wextreme` would be a very extreme delta and it would be in the 99th percentile of a normal distribution with mean 0 and standard deviation 45. So to obtain a $\sigma$ of 45, 

```{r}
pnorm(30, mean = 0, sd=9)
pt(45, 1)
```

$\delta_{cluster} \sim \mathcal{N}(0,\sigma_{cluster})$

$\sigma_{cluster} \sim \mathcal{N}(0, 18)$

```{r}
hist(rnorm(1000, mean=0, sd=18), breaks=50) 

```

I've stuck with half normals because while clone has hundreds of levels, Site and Provenance only have 7 and year only 14 (15?)
 
## Centering

Factors that have a lot of levels all with limited data, like clone, will probably sample best if non-centered.

Some of my factors are very unbalanced with some levels very well represented and others not and could benefit from partial decentering. However, brms automatically non-centers everything. If it works, then don't worry here.

