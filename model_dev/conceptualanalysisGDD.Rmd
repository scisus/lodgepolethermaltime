---
title: "Phenology model workflow"
author: "C. Susannah Tysor"
date: '2021-08-24'
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup}

library(dplyr)
library(ggplot2)
library(zoo)
library(flowers)
library(dplyr)
library(knitr)
library(tidyr)

knitr::opts_chunk$set(echo = TRUE)
source('../phenology_functions.R')
```

# Conceptual Analysis

I have a record of days that lodgepole pine were recorded flowering or not flowering during the general flowering period. Trees were not observed every day and the start or end of the flowering period may have been missed.

The flowering observations ($y$) were simplified to three states - before flowering, flowering, past flowering. States are used to infer two of four events (1-last day before flowering, 2-first day flowering, 3-last day flowering, 4-first day past flowering). . The amount of forcing accumulated at each event day was calculated using Risto Sarvas's 1972 curve.

I want to know how much forcing after January 1 must accumulate for events 2 and 3 - the flowering state - to occur.

$y_i \sim \mathcal{N}(f_i, \sigma)$

I wish to account for several kinds of structure in the data:

- year of observation
- site where tree was grown
- genotype of the tree
- genotype (individual tree)

and variation due to provenance climate summarised at MAT

So

$f_i = \mu + \beta MAT_i + delta_{site,i} + \delta_{year,i} + \delta_{genotype,i} + \delta_{genotype,i}$

where $\mu$ is the average amount of forcing it takes for a tree to reach an event and the $\delta$s describe how much each level in each factor (site, prov, year, genotype) is offset from the population mean amount of forcing required to reach the event.

I want priors on parameters to be regularizing and weakly informative.

# Define observational space

There are several thousand observations of each event. Each observation is the amount of forcing units accumulated when the event occurs for a given tree. 

So, how much forcing is accumulated over the year? I use the sites in my study and all possible years in my climate dataset (1945-2012).

```{r}

# forcing units for 15 years and at sites included in this study
forcing <- read.csv('~/lodgepolethermaltime/data/dailyforc_1945_2012.csv', header=TRUE) 
  
ggplot(forcing, aes(x=DoY, y=sum_forcing, colour = interaction(Site,Year))) +
  geom_line() +
  theme(legend.position = "none") +
  ggtitle("forcing (gdd) accumulated at Day of Year")



```

What are reasonable amounts of forcing? Lodgepole in BC flower in late spring - pollination occurs, according to Owens in late May and June. I will generously set this as May 01 to June 30.
[maybe should be more generous and use april?]

```{r}
# likely Day of Year limits for flowering
early_limit <- as.numeric(strftime("2020-05-01", format = "%j"))
late_limit <- as.numeric(strftime("2020-06-30", format = "%j"))

ff <- dplyr::filter(forcing, DoY > early_limit & DoY < late_limit)

ggplot(ff, aes(x=sum_forcing)) +
         geom_histogram(bins=60) +
  ggtitle("Range of forcing accummulations May 1 - June 30")

ggplot(ff, aes(x=DoY, y=sum_forcing, colour = interaction(Site,Year))) +
  geom_line() +
  theme(legend.position = "none") +
  ggtitle("forcing (gdd) accumulated at Day of Year", subtitle = "May 1 - June 30")


```


```{r}
# Early and Late
may01 <- as.numeric(strftime("2020-05-01", format = "%j"))
may31 <- as.numeric(strftime("2020-05-31", format = "%j"))

may15 <- as.numeric(strftime("2020-05-15", format = "%j"))
jun30 <- as.numeric(strftime("2020-06-30", format = "%j"))

ffstart <- dplyr::filter(forcing, DoY > may01 & DoY < may31)
range(ffstart$sum_forcing)

ffend <- dplyr::filter(forcing, DoY > may15 & DoY < jun30)
range(ffend$sum_forcing)

```
Flowering is more likely to start in the first part (`r range(ffstart$sum_forcing)` forcing units) and end in the second part (`r range(ffend$sum_forcing)` forcing units) of this time period.

Each event is associated with a year, site, genotype, and genotype. There are 14 years, 7 sites, 259 genotypes, and 748 individual trees (genotypes).

# Construct summary statistics

Histograms of $y_i$ and each $\delta_{cluster}$.

# Model development

$y_i$ are the observations of accumulated forcing. They are positive and continuous and should be between about 0 and 1000. 

$y_i$'s value can be modeled as coming from a distribution with a mean forcing accumulation ($f_i$) and standard deviation $\sigma$ that represents our uncertainty in the observation - how good our temperature measurements are, how good the forcing unit accumulation function is, and whether the event was observed on the correct day. 

## sigma

Sigma could potentially be relatively large because of lackadaisical sampling and compounding errors through censoring, multiple observers, and errors in accumulated forcing measurements. I think an extreme upper limit is probably about 2 weeks of forcing. 

```{r}

# get 7 & 14 day forcing accumulations

janjun <- forcing %>%
  filter(DoY < late_limit) 


fortforc <- janjun %>%
  group_by(Site, Year) %>%
  summarise(fortforc = rollsum(forcing, 14))

# fortforce <- early %>%
#   group_by(Site, Year) %>%
#   summarise(fortforce = rollsum(forcing, 14))

fextreme <- quantile(fortforc$fortforc, 0.99) #end

#feextreme <- quantile(fortforce$fortforce, 0.99) # start

```

The amount of forcing that can accumulate over any two week period between January and June can be quite large - 99th percentile is `r fextreme`. The sd required to obtain these values in a normal distribution is:

```{r}

ggplot(fortforc, aes(x=fortforc)) +
  geom_histogram() +
  ggtitle("Forcing accumulation over 14 day periods Jan-Jun") +
  geom_vline(xintercept = mean(fortforc$fortforc))

# normal
pnorm(fextreme, 0, sd=60) # sd to cap at extreme #50 prob fine too
hist(rnorm(1000, 0, sd=60), breaks=50) 

# pnorm(feextreme, 0, sd = 40)
# hist(rnorm(1000, 0, sd = 40))

#student
pt(fextreme, 1)
hist(rt(1000, 1), breaks = 50)
```
And distributions that produce these standard deviations, for sampling sigma are
```{r}
pnorm(60, 0, 20) # 15 probably lower limit when using 50sd
pt(60, 1)

# pnorm(40, 0, 12)
# pt(55, 1)
```
So,

$y_i ~ \mathcal{N}(f_i, \sigma)$

$\sigma \sim |\mathcal{Normal}(0, 50)|$

$f_i$ is a function of $\mu$ and the $\delta$ offsets. 

## mu

$\mu$ represents the population average for forcing required to achieve the flowering event of interest. 

```{r}

ffstart <- dplyr::filter(forcing, DoY > may01 & DoY < may31)
range(ffstart$sum_forcing)

ffend <- dplyr::filter(forcing, DoY > may15 & DoY < jun30)
range(ffend$sum_forcing)

ffs1 <- quantile(ffstart$sum_forcing, 0.01)
ffe1 <- quantile(ffend$sum_forcing, 0.01)
ffs99 <- quantile(ffstart$sum_forcing, 0.99)
ffe99 <- quantile(ffend$sum_forcing, 0.99)



```
It must be positive and continuous. Values less 5 and greater than 1000 would be quite unbelievable for any phase.

For starting, values less than `r ffs1` and greater than `r ffs99` would be very surprising.
For finishing, values less than `r ffe1` and greater than `r ffe99` would be very surprising.

### mu start

For start events



```{r}
pnorm(ffs99, mean = (ffs1+ffs99)/2, sd = 60) #start
hist(rnorm(1000, 233, 60), breaks=60)
hist(rt(1000, 25, ncp = 233), breaks=60)

```
$\mu \sim \mathcal{N}(335,85)$

### mu end

For end events:

$\mu \sim \mathcal{N}(555,150)$

```{r}
pnorm(ffe99, mean = (ffe1 + ffe99)/2, sd = 100) #end
hist(rnorm(1000, 438, 100), breaks=60)
```
These are very weakly informative - I could use more detailed prior information from work by Owens regarding dates and heatsums.

### whole period
I could be even broader and use the same prior for both. Because the data is skewed, a skewed distribution, like gamma, might make more sense.

```{r}
ffperiod <- dplyr::filter(forcing, DoY > may01 & DoY < jun30)
range(ffperiod$sum_forcing)

ffp1 <- quantile(ffperiod$sum_forcing, 0.01)
ffp99 <- quantile(ffperiod$sum_forcing, 0.99)

pnorm(ffp99, mean = (ffp1 + ffp99)/2, sd = 100) #end
hist(rnorm(1000, 400, 100), breaks=60)
hist(ff$sum_forcing, breaks=50)
# gamma k shape = mean^2/sd^2
k <- mean(ff$sum_forcing)^2/sd(ff$sum_forcing)^2
# gamma theta scale = sd^2/mean, rate = 1/theta
theta <- sd(ff$sum_forcing)^2/mean(ff$sum_forcing)
hist(brms::rskew_normal(1000, 100, 100, 2), breaks = 50)
hist(rgamma(1000, shape = k, scale = theta), breaks = 50)
hist(rnorm(1000, mean = 400, sd = 100), breaks = 50)
```
Nice thing about gamma distribution is it's always positive, like forcing values, and accommodates skew.


## delta 

The $\delta$ effects are modeled as offsets from $\mu$, thus the superpopulation mean must be 0. Individual effects, however, may vary by $\sigma_{factor}$

A flowering period of 2 weeks for a population would be very long and a flowering period of a week very long for an individual tree, so an effect ($\delta$) that changed the timing of flowering by even a few days would be meaningful. An delta that shifted flowering by 1 weeks would be quite extreme. How much forcing can accumulate in 1 week prior to an event?

[Since there aren't extreme variations in the length of flowering period, using the first part of the flowering period might be a better guide for this. Currently using January - June]

```{r}
week_forcing <- janjun %>%
  group_by(Site, Year) %>%
  summarise(sum_forcing_week = zoo::rollsum(forcing, 7))

ggplot(week_forcing, aes(x=sum_forcing_week)) +
  geom_histogram() +
  ggtitle("Forcing accumulation over 1 week periods from January 1 to June 30") +
  geom_vline(xintercept = mean(week_forcing$sum_forcing_week))

# 90th percentile of forcing that can accumulate in a week
wextreme <- quantile(week_forcing$sum_forcing_week, .99) # because forcing accumulates so much faster at the end of june when flowering is quite unlikely, capping at 90%

pnorm(wextreme, mean=0, sd=30) # what sd caps at extreme forcing accumulation


```
`r wextreme` would be a very extreme delta and it would be in the 99th percentile of a normal distribution with mean 0 and standard deviation 45. So to obtain a $\sigma$ of 45, 

```{r}
pnorm(30, mean = 0, sd=9)
pt(45, 1)
```

$\delta_{cluster} \sim \mathcal{N}(0,\sigma_{cluster})$

$\sigma_{cluster} \sim \mathcal{N}(0, 18)$

```{r}
hist(rnorm(1000, mean=0, sd=18), breaks=50) 

```

I've stuck with half normals because while genotype and genotype have hundreds of levels, Site only has 7 and year only 14 (15?)

## beta
Beta sampling distribution must include 0 as we don't know if there's an effect and it's centered on 0 because I don't have any reason to believe an effect would be positive or negative. How wide its sampling distribution will be depends realistic forcing ranges and MAT. MAT at my sites ranges from -0.7 to 6.8 $^\circ$C.
If only provenance climate controlled GDD requirements, then maximum size of beta is the maximum accumulated forcing difference between sites divided by the MAT range. 

```{r beta}
forcing %>%
  filter(DoY == 181) %>%
  select(Year, Site, sum_forcing) %>%
  summarise(maxdiff = range(sum_forcing))
```

The maximum difference between sites is about 800 GDD and the temperature difference between provenances is about 8 degrees, so, if MAT expained the entire GDD required, $\beta$ would be about 100.

<!-- But that's a very unrealistic assumption based on everything we know about spring phenology - and the experience of generalized overlap in the seed orchards. I think even 50 would be a shocking result -->

```{r betadist}
sdx = 25
pnorm(100, mean = 0, sd = sdx)
hist(rnorm(1000, 0, sdx))
```
 
## Centering

Factors that have a lot of levels all with limited data, like genotype, will probably sample best if non-centered.

Some of my factors are very unbalanced with some levels very well represented and others not and could benefit from partial decentering. However, brms automatically non-centers everything. If it works, then don't worry here.



