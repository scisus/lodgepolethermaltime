---
  title: "Model methods"
author: "C. Susannah Tysor"
date: '2021-06-25'
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}

library(flowers)
library(dplyr)
library(brms)
library(ggplot2)
library(tidyr)
library(tidybayes)
library(forcats)
library(ggbeeswarm)

knitr::opts_chunk$set(echo = TRUE)
theme_set(theme_dark())

source('phenology_functions.R')
```

## Data

Phenology data is available in the `flowers` R package published on Github [ARCHIVE ON ZENODO]

```{r data}
phendat <- flowers::lodgepole_phenology_event %>%
  mutate(Tree = paste0(Orchard, Clone, X, Y)) # create a unique Tree identifier since original data doesn't always have one

phenf <- prepare_data(phendat, forcing = "gdd")

ggplot(phenf, aes(x = sum_forcing, color = Event_Label, linetype = Sex)) +
  stat_ecdf() +
  labs("Cumulative distribution of accumulated forcing for flowering events", caption = "raw data") +
  scale_colour_viridis_d() +
  theme_dark(base_size = 18) +
  ylab("") +
  xlab("Heatsum")

# create 4 datasets for 4 models

fbdat <- filter_sex_event(sex = "FEMALE", event = "begin", phenf)
fedat <- filter_sex_event(sex = "FEMALE", event = "end", phenf)

mbdat <- filter_sex_event(sex = "MALE", event = "begin", phenf)
medat <- filter_sex_event(sex = "MALE", event = "end", phenf)



```

```{r climdat}
siteclim <- read.csv("../lodgepole_climate/processed/PCIC_all_seed_orchard_sites_adjusted.csv")
provclim <- read.csv("../phd/data/Lodgepole_SPU_climsum.csv")
histclim <- read.csv("data/all_clim_PCIC.csv")
futclim <- read.csv("../lodgepole_climate/processed/future_daily_temps.csv")
spudat <- read.csv("../phd/data/OrchardInfo/LodgepoleSPUs.csv")
```

```{r ordering}
# order provenances and sites from warmest to coldest
siteMAT <- siteclim %>% 
  mutate(Year = lubridate::year(Date)) %>%
  group_by(Site) %>%
  summarise(MAT = mean(mean_temp_corrected)) %>%
  arrange(MAT)

sitefactororder <- siteMAT$Site

provMAT <- provclim %>% select(SPU_Number, MAT) %>%
  full_join(spudat) %>%
  filter(!is.na(Repro_Data)) %>%
  select(MAT, SPU_Name) %>%
  distinct() %>%
  arrange(MAT)

provfactororder <- provMAT$SPU_Name %>% 
  stringr::str_replace_all(pattern = "\\s", replacement = "\\.")

yearMAT <- siteclim %>% 
  mutate(Year = lubridate::year(Date)) %>%
  right_join(data.frame(Year = as.numeric(unique(phenf$Year)))) %>%
  group_by(Year) %>%
  summarise(MAT = mean(mean_temp_corrected)) %>%
  arrange(MAT)

yearfactororder <- yearMAT$Year

```
Make censorship tables (proportion?)
```{r}

begincensor <- phenf %>% filter(Event_Obs == 2)

filter(begincensor, censored == "left") %>%
  select(Site, Sex) %>%
  group_by(Site, Sex) %>%
  summarise(n=n()) %>%
  pivot_wider(names_from = Sex, values_from = n)

endcensor <- phenf %>% filter(Event_Obs == 3)

filter(endcensor, censored == "right") %>%
  select(Site, Sex) %>%
  group_by(Site, Sex) %>%
  summarise(n=n()) %>%
  pivot_wider(names_from = Sex, values_from = n)

#proportion
phenf %>% filter(Event_Obs %in% c(2,3)) %>%
  group_by(Sex, Event_Label) %>%
  mutate(n = n()) %>%
  group_by(Sex, Event_Label, censored) %>%
  summarise(count = n(), proportion = round(count/n, 2)) %>%
  select(-count) %>%
  distinct() %>%
  filter(censored %in% c("left", "right"))

```

## Model

We built separate hierarchical Bayesian intercept-only factor models of the accumulated forcing at each of the four flowering events of interest: start of receptivity (female begin), end of receptivity (female end), start of pollen shed (male begin), and end of pollen shed (male end).

Ideally, the likelihood of begin and end of flowering observations $y_i$ would

$y_i \sim \mathrm{Normal}(\phi_i, \sigma)$

However, interval and end censoring
The likelihood is modified for the 37 to 65% of end censored observations. 

Flowering start data is left censored when a tree is already flowering when it is first observed, so the likelihood is calculated with a cumulative normal distribution function.

$\mathrm{y_i} \sim \mathrm{Cumulative Normal}(\phi_i,\sigma)$

Flowering end data is right censored when a tree is never observed past flowering and a complementary cumulative normal distribution function is used for the likelihood. 

$\mathrm{y_i} \sim \mathrm{Complementary Cumulative Normal}(\phi_i, \sigma)$.

Mean $\phi_i$ is the sum of the overall population mean $\mu$ and offsets $\delta$ for each level of factors Site, Provenance, Year, and Clone.

$\mathrm{\phi_i} = \mu + \delta_{Site, i} + \delta_{Provenance, i} + \delta_{Year, i} + \delta_{Clone, i}$

Priors limit parameter estimates to forcing accumulations possible at our sites during late spring, when lodgepole pine are known to flower in British Columbia (@owensReproductiveBiologyLodgepole2006). Offset standard deviations $\sigma_{factor}$ were roughly constrained by both estimates of possible forcing accumulation and the approximately known length of the flowering period. Possible forcing accumulation ranges were calculated using daily PCIC weather data from 1945-2012 at all of our sites. As Site, Provenance, and Year have relatively few levels with which to estimate $\sigma_{factor}$, half normal priors with their relatively thin tails were used to help constrain the parameter. Additional details on prior choice can be found in the conceptual analysis (supplementary materials).

Priors for the begin models differ for those of the end models as forcing accumulates faster in later spring than early spring and flowering must begin before it can end.

Priors for the start of receptivity and pollen shed models were
$$\begin{align}
\mu & \sim \mathrm{Normal}(400,100) \\
\sigma & \sim \left|\mathrm{Normal}(0,15)\right| \\
\sigma_{factor, j} & \sim \left|\mathrm{Normal}(0,9)\right| \\
\end{align}$$



```{r model, cache = TRUE, echo = FALSE, include = FALSE}
# This model block is faster if you run models in parallel
# initialize parameter values on the right order of magnitude
initpars <- lapply(1:6, function(id) list(sigma = 30, Intercept = 300))

# model formula
bform <- brmsformula(sum_forcing | cens(censored, upper) ~ 1 + (1|Site) + (1|Provenance) + (1|Clone) + (1|Year) + (1|Tree))

# model prior
bprior <- c(prior("normal(400,100)", class = "Intercept"),
            prior("normal(0,15)", class = "sigma"),
            prior("normal(0,9)", class = "sd"))
niter <- 4000
ncores <- 6
nchains <- 6

fbfit <- brm(bform, data = fbdat,
             save_model = "female_begin.stan",
             file = "female_begin",
             prior = bprior,
             inits = initpars,
             iter = niter,
             cores = ncores,
             chains = nchains,
             sample_prior = TRUE,
             save_pars = save_pars(all = TRUE),
             file_refit = "on_change")
#fbfit <- readRDS("female_begin.rds")

fefit <- brm(bform, data = fedat,
             save_model = "female_end.stan",
             file = "female_end",
             prior = bprior,
             inits = initpars,
             iter = niter,
             cores = ncores,
             chains = nchains,
             sample_prior = TRUE,
             save_pars = save_pars(all = TRUE),
             file_refit = "on_change")
#fefit <- readRDS("female_end.rds")

mbfit <- brm(bform, data = mbdat,
             save_model = "male_begin.stan",
             file = "male_begin",
             prior = bprior,
             inits = initpars,
             iter = niter,
             cores = ncores,
             chains = nchains,
             sample_prior = TRUE,
             save_pars = save_pars(all = TRUE),
             file_refit = "on_change")
#mbfit <- readRDS("male_begin.rds")

mefit <- brm(bform, data = medat,
             save_model = "male_end.stan",
             file = "male_end",
             prior = bprior,
             inits = initpars,
             iter = niter,
             cores = ncores,
             chains = nchains,
             sample_prior = TRUE,
             save_pars = save_pars(all = TRUE),
             file_refit = "on_change")
#mefit <- readRDS("male_end.rds")

modells <- list(fb = readRDS("female_begin.rds"),
                fe = readRDS("female_end.rds"),
                mb = readRDS("male_begin.rds"),
                me = readRDS("male_end.rds"))

```
Models were fit in Stan (`rstan` vers. 2.21.2 [@standevelopmentteam2020]) via the R (R version 4.0.3 (202-10-10)) package `brms` (vers. 2.15.0 [@Burkner2017a]). Stan uses the No-U-Turn Sampler, an efficient Markov Chain Monte Carlo method that extends the Hamiltonian Monte Carlo algorithm [@carpenter2017], to sample the joint posterior. 

### Diagnostics
We ran `r nchains` independent chains of `r niter` iterations each. `r niter/2` warmup iterations were dropped from each chain for `r nchains * (niter/2)` total samples. Model convergence and performance were considered good; $\hat R$ was $< 1.01$ and bulk and tail effective sample size was more than 100x the number of chains for all parameter values in all models [@vehtari2019]. There were no divergences. Visual inspection of energy plots and rank plots showed acceptable sampling behavior.


# Results


```{r samplepost}
nsamp <- 2000
seed <- 1657
```

For efficiency, `r nsamp` posterior samples were used for plotting results.

## Means
```{r means, cache=TRUE}
#vars <- tidybayes::get_variables(fbfit)

labdf <- data.frame(Sex = c("FEMALE", "FEMALE", "MALE", "MALE"), event = c('begin', 'end', 'begin', 'end'), model = c('fb', 'fe', 'mb', 'me'))

gather_means_draws <- function(mod) {
  mod %>% gather_draws(b_Intercept, n = nsamp, seed = seed) 
}

means <- purrr::map(modells, gather_means_draws) %>%
  bind_rows(.id = "model") %>%
  left_join(labdf)

ggplot(means, aes(y = fct_rev(model), x = .value, colour = event, linetype = Sex)) +
  stat_halfeye() +
  scale_colour_viridis_d() +
  ggtitle("Population mean") +
  ylab("") +
  xlab("Forcing")


```
Overall variation in flowering is ~15 forcing units for start and 17 for end. In general, variation is smaller for start events than end events, likely because forcing increases monotonically.

Estimates for variation among Year, Site, and Provenance are relatively uncertain because the number of levels within each of these factors was small (7-15), while there were hundreds of clones and trees.

Within-clone variance (sd Tree) is very low, but higher for males than females. Mean estimates of variation within provenance (among Clone variation) is higher than variation among provenances, but the posterior is quite wide for Provenance and the posterior has a great deal of weight beyond the upper limits of the Clone estimates.

Year explains more of the variation than all other factors except for the female end model where Site is more important.

Female begin: Year, Clone, Site, Provenance, Tree
Male begin: Year, Clone, Provenance, Site, Tree
Female end: Site, Year, Clone, Provenance, Tree
Male end: Year, Site, Clone, Provenance, Tree

Year: me, fe, mb, fb
Site: fe, me, fb, mb
Prov: me, fe, fe, mb
Clone: fe, me, fb, mb
Tree: me, mb, fb, fe

## Variation

```{r variation, cache = TRUE}


gather_var_draws <- function(mod) {
  mod %>% gather_draws(`sd_.*`, `sigma`, regex = TRUE, n = nsamp, seed = seed) 
}

variation <- purrr::map(modells, gather_var_draws) %>%
  bind_rows(.id = "model") %>%
  left_join(labdf) %>%
  mutate(.variable = case_when(.variable != "sigma" ~ stringr::str_sub(.variable, 4, -12),
                               .variable == "sigma" ~ "sigma")) %>%
  mutate(.variable = factor(.variable)) %>%
  mutate(.variable = forcats::fct_relevel(.variable, "sigma", "Year", "Site", "Provenance", "Clone", "Tree"))

ggplot(variation, aes(y = fct_rev(.variable), x = .value, colour = .variable, linetype = Sex)) +
  stat_pointinterval(position = "dodge") +
  scale_colour_viridis_d() +
  ggtitle("Standard deviation of population mean and offsets") +
  ylab("") +
  xlab("Forcing") +
  facet_wrap("event") +
  theme(legend.position = "bottom") +
  guides(color = FALSE, size = FALSE) +
  theme_dark(base_size = 18)
```
Effects for Tree are generally quite small and are moderate for Provenance. Clone has a wide range of possible effects. PGTIS and PRT have relatively large effects for the end of flowering, tending to stop flowering at a larger forcing amount. (Maybe because of censoring?) Provenances have similar ranked effects across models and events, tending to skew events earlier or later by a small amount of forcing. 

## Offsets
```{r offsets, cache=TRUE}

gather_offset_draws <- function(mod) {
  mod %>% gather_draws(`r_.*`, regex = TRUE, n = nsamp, seed = seed) 
}

offsets_raw <- purrr::map(modells, gather_offset_draws) %>%
  bind_rows(.id = "model") %>%
  left_join(labdf) #%>%

# turn brms .variable names into useful names (slow)
varlevel <- offsets_raw$.variable %>% stringr::str_split_fixed("[_\\[\\,]", n=4) %>% data.frame() %>%
  select("X2", "X3")
colnames(varlevel) <- c("factor", "level")

# order factors and factor levels
yearclonetree <- filter(varlevel, factor %in% c("Year", "Clone", "Tree")) %>% distinct()
yctorder <- sort(yearclonetree$level)

spyctorder <- c(sitefactororder, provfactororder, yctorder)

offsets <- offsets_raw %>% cbind(varlevel) %>%
  ungroup() %>%
  mutate(factor = forcats::fct_relevel(factor, "Year", "Site", "Provenance", "Clone", "Tree")) %>%
 mutate(level = forcats::fct_relevel(level, spyctorder)) 

offsets_summary <- offsets %>%
  group_by(model, Sex, event, factor, level) %>%
  median_hdci(.value, .width = c(0.5, 0.89)) %>%
  ungroup()


offsets_summary %>%
  select(model, Sex, event, factor, level, .value, .point) %>% distinct() %>%
  ggplot(aes(y=.value, x = model)) +
  geom_quasirandom(alpha = 0.5) +
  facet_wrap("factor") +
  ggtitle("Offset medians", subtitle = "Effect of clones, provenance, site, tree, and year") +
  geom_hline(yintercept = 0, linetype =3, colour = "darkgray") +
  theme_bw() +
  ylab("Forcing") 


siter <- filter(offsets, factor == "Site") %>%
  mutate(level = forcats::fct_relevel(level, sitefactororder))

provr <- filter(offsets, factor == "Provenance") %>%
  mutate(level = forcats::fct_relevel(level, provfactororder))

yearr <- filter(offsets, factor == "Year") %>%
  mutate(level = forcats::fct_relevel(level, as.character(yearfactororder)))

ggplot(siter, aes(y=level, x = .value)) +
  stat_pointinterval() +
  facet_grid(event ~ Sex) +
  ggtitle("Site offsets", subtitle = "Sites ordered warmest to coldest MAT") +
  theme_bw() +
  ylab("Forcing") +
  geom_vline(xintercept = 0, linetype =3, colour = "darkgray") +
  xlim(c(-90,90))

ggplot(provr, aes(y=level, x = .value)) +
  stat_pointinterval() +
  facet_grid(event ~ Sex) +
  ggtitle("Provenance offsets", subtitle = "Provenances ordered warmest to coldest MAT") +
  theme_bw() +
  ylab("Forcing") +
  geom_vline(xintercept = 0, linetype =3, colour = "darkgray")  +
  xlim(c(-90,90))

ggplot(yearr, aes(y=level, x = .value)) +
  stat_pointinterval() +
  facet_grid(event ~ Sex) +
  ggtitle("Year offsets", subtitle = "Years ordered warmest to coldest MAT") +
  theme_bw() +
  ylab("Forcing") +
  geom_vline(xintercept = 0, linetype =3, colour = "darkgray")  +
  xlim(c(-90,90))

```

# Retrodictions


## General predictions

```{r general_predictions}

# simulate new data from the model for n_lct new levels of each factor of the model. n_lct is a numeric vector of length 3 c(number of new sites/provenances/years, number of clones per provenance, number of trees per clone) Draws for factor effects are from N(0, sigma_cluster). Using nsamples draws from the posterior.

simulate_from_model <- function(data, model, n_lct = c(5,10,2), nsamples = nsamp, seed = seed, cores = 6) {
  # retrodict "true"
  yrep <- add_predicted_draws(newdata = data, model = model, n = nsamples, seed = seed, cores = cores, prediction = "prediction") %>%
    mutate(prediction_type = "retrodiction - uncensored") 
  
  # censor yrep based on censoring points in the raw data
  yrep_censored <- yrep %>%
    mutate(prediction_temp = case_when(censored == "interval" & prediction < sum_forcing ~ sum_forcing,
                                       censored == "interval" & prediction > upper ~ upper,
                                       censored == "interval" & (prediction >= sum_forcing) & (prediction <= upper) ~ prediction,
                                       
                                       censored == "right" & prediction >= sum_forcing ~ sum_forcing,
                                       censored == "right" & prediction < sum_forcing ~ prediction,
                                       
                                       censored == "left" & prediction < sum_forcing ~ prediction,
                                       censored == "left" & prediction >= sum_forcing ~ sum_forcing),
           prediction_type = "retrodiction - censored") %>%
    select(-prediction) %>%
    rename(prediction = prediction_temp)
  

  # simulate data for fully crossed version of real dataset. This is 82,000+ observations and my computer can't handle that unless I use *very* few posterior samples
  
  crossdat <- data %>% tidyr::complete(Sex, event, Year, Site, tidyr::nesting(Provenance, Clone, Tree)) %>%
    tidyr::complete(Year, nesting(Site, Tree)) %>%
    select(Year, Site, Tree, Provenance, Clone) %>%
    distinct()

  ypred_fullcross <- tidybayes::add_predicted_draws(newdata = crossdat, model = model, n = 30, seed = seed, cores = cores, prediction = "prediction") %>%
    mutate(prediction_type = "prediction - full cross")
  
  # simulate data from new levels (out-of-sample predictions). The newdata simulation code took an embarrassingly long time to figure out
  nlevels <- n_lct[1] # how many sites, provenances, and years
  lv <- as.character(1:nlevels)
  nc <- n_lct[2] # clones per prov
  nt <- n_lct[3] # trees per clone
  
  Year <- data.frame(Year = lv)
  newdata <- data.frame(Site = rep(lv, nc*nt),
                        Provenance = rep(lv, nc*nt),
                        Clone = as.character(rep(1:(nlevels*nc), nt))) %>%
    tidyr::complete(Site, tidyr::nesting(Provenance, Clone)) %>%
    arrange(Site, Provenance, Clone) %>%
    mutate(Tree = as.character(1:n())) %>%
    merge(Year) %>%
    complete(Site, Provenance, Year)
  
  ypred_newlevels <- add_predicted_draws(newdata = newdata, model = model, allow_new_levels = TRUE, sample_new_levels = "gaussian", n = nsamples, seed = seed, cores = cores, prediction = "prediction") %>%
    mutate(prediction_type = "prediction - new levels")

  preds <- rbind(yrep, yrep_censored, ypred_fullcross, ypred_newlevels) %>%
    mutate(Sex = unique(data$Sex), event = unique(data$event))
  
  return(preds)
}

alldatls <- list(fbdat, fedat, mbdat, medat)
alldat <- rbind(fbdat, fedat, mbdat, medat)

allsim <- purrr::map2(alldatls, modells, function(x,y) {simulate_from_model(data = x, model = y, nsamples = 200, seed = seed)}) %>%
  bind_rows()


#may15doy <- lubridate::yday("2021-05-15")

#may15 <- histclim %>% 
 # filter(DoY == may15doy, forcing_type == "gdd") 

ggplot(alldat, aes(x = sum_forcing, y = "observations" )) +
  stat_dotsinterval( .width = c(0.5, 0.89), point_interval = median_qi) +
  stat_slab(data = allsim, 
                    aes(x = prediction, y = prediction_type, group=.draw),
                    .width = c(0.5, 0.89), point_interval = median_hdci, 
                    slab_color = "gray65", alpha = 1/10, fill = NA) +
  stat_pointinterval(data = allsim, aes(x = prediction, y = prediction_type), 
                     .width = c(0.5, 0.89), point_interval = median_hdci ) +
 # stat_dots(data = may15, aes(x = sum_forcing, y = "Forcing at May 15")) +
  theme_bw() +
  facet_grid(Sex ~ event) +
  labs(title = "Modeled and observed flowering events", subtitle = "50 & 89% quantile intervals for observations \nand HCDI intervals for model predictions", caption = "200 samples from the posterior, 5 for fully crossed predictions") +
  xlab("Accumulated forcing") +
  ylab("")

```

We used the model to simulate four data sets. First we retrodicted flowering forcing for the observed combinations of trees, clones, years, provenances, and sites (retrodiction - uncensored). Then we censored that data based on the censoring points recorded in our observations (retrodiction - censored). We expect the censored retrodictions to match our observations relatively well. 

We also predicted flowering forcing for a fully crossed version of our original dataset and for new sites, years, provenances, clones, and trees. Since the fully-crossed version of our originally observed data set is 82,768 rows for each sex + event, only 5 samples from the posterior were used to simulate each observation. For new levels, we predicted 1500 forcing observations for all 4 flowering events. We sampled offsets for 5 new sites, years and provenances from the superpopulation posterior distributions for each factor offset ($\mathrm{Normal}(0, \sigma_{factor})$). Each provenance was represented by 10 clones with 2 ramets each.

All simulations used the same 200 draws from the posterior, except for the fully crossed version which used the same 5 which were a subset of the previous 200.

# Add days to preds

See functions in retrodiction functions for this.

```{r predictdaysspecific, fig.height=8}

# first get DoY predictions for specific predictions & retrodictions (uncensored, fully crossed)
# filter simulations for only real sites and years, not new levels and simplify to only columns needed for matching 
specificsim <- filter(allsim, prediction_type %in% c("retrodiction - uncensored", "prediction - full cross")) %>%
  ungroup() %>%
  select(Year, Site, prediction) %>%
  distinct() 


# prepare dataframes a and b for interval finding by splitting into lists and ensuring that the climate list (a) and the phenology list (b) contain information for the same sites and years. a and b must both have Site and Year columns
split_df_to_lists <- function(a, b) {
  lista <- split(a, f = list(a$Site, a$Year), drop = TRUE)
  listb <- split(b, f = list(b$Site, b$Year), drop = TRUE)
  
  # check that all sites and years in the phenology frame are in the climate frame
  assertthat::assert_that(all(names(listb) %in% names(lista))) # all entries in B must be in A
  
  # subset lista so it only contains Site x Year that also occur in B
  ainb <- lista[names(listb)] 
  
  assertthat::are_equal(names(ainb), names(listb)) 
  
  return(list(listainb = ainb, listb = listb))
}

forcing_to_doy <- function(a, b, aforce, bforce, newdoycolname) {
  # prepare dataframes for interval finding by splitting into lists
  splitdfs <- split_df_to_lists(a, b)
  
  df <- purrr::map2(splitdfs$listainb, splitdfs$listb, find_day_of_forcing, aforce = aforce, bforce = bforce) %>% # find DoY in A corresponding to each sum_forcing in B
    purrr::map_dfr(bind_rows) # combine into a single dataframe
  
  names(df)[which(names(df) == "newdoycol")] <- newdoycolname 
  
  return(df)
}

# given dataframes adf (climate) and bdf (phenology) identify the day of year corresponding to reaching each sum_forcing bcol in df. adf must have a sum_forcing column identified by name acol and a DoY column and b must have a sum_forcing column identified with name bcol. name the new_day_col arg with a string
find_day_of_forcing <- function(adf, bdf, aforce, bforce) {
  
  # what row in a contains the interval for entries in b. Add 1 to the index because phenological events require the threshold to be reached. this introduces error, but is unavoidable in some direction.
  a_index <- findInterval(bdf[[bforce]], adf[[aforce]]) + 1
  
  
  # add a column to b for Day of Year and extract the correct Day of year from a using the index
  bdf$newdoycol <- adf$DoY[a_index] 
  
  # when sum_forcing in b is exactly identical to sum_forcing in b, a_index will be +1 day. Re-write those 
  identical_forcing_index <- which(bdf[[bforce]] %in% adf[[aforce]])
  bdf$newdoycol[identical_forcing_index] <- bdf$newdoycol[identical_forcing_index] - 1
  
  # (indirectly) test whether the correct day of year is being assigned to the correct forcing unit - for any site x year, sorting by sum_forcing_rep or newdoycol should produce the same ordering of newdoycol in bdf
  
  # order_by_sumforcing <- arrange(bdf, bforce, newdoycol)$newdoycol
  # order_by_newdoycol <- arrange(bdf, newdoycol)$newdoycol
  # 
  # assertthat::are_equal(order_by_sumforcing, order_by_newdoycol)
  
  return(bdf)
}


```
